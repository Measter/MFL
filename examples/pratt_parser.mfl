import std::term
import core::String

proc entry [var argc u64, var argv u8**] to [] {
    cond {
        argc@ 2 != {
            "USAGE: " term::write argv@@ String::from_cstr term::write
            " \"<expr>\"" term::writeln
            return
        }
    }

    argv@ 1+@ String::from_cstr dup
    term::write " = " term::write
    Scanner::new Eval::new

    var eval Eval
    eval!

    eval Eval::advance
    eval Eval::parse_expression
    eval.sum@ term::write_si_ln
}

const Prec_None [u8] { 0 }
const Prec_Term [u8] { 1 }
const Prec_Factor [u8] { 2 }
const Prec_Unary [u8] { 3 }
const Prec_Group [u8] { 4 }

struct Eval {
    scanner Scanner,
    current Token,
    previous Token,
    sum s64,

    struct Rule {
        prefix proc[Eval&] to [],
        infix proc[Eval&] to [],
        prec u8
    }

    proc new [Scanner] to [Eval] {
        TokenKind_Eof 0 "" Token dup 0 Eval
    }

    proc advance [var this Eval&] to [] {
        this@.current@ this@.previous!

        while true {
            this@.scanner Scanner::scan
            this@.current!

            cond {
                this@.current.kind@ TokenKind_Unknown != {return}
                else {
                    "Unknown input: " term::write this@.current.lexeme@ term::writeln
                }
            }
        }
    }

    proc get_rule [u8] to [Rule] {
        cond {
            TokenKind_LeftParen = { ^grouping ^null Prec_Group }
            TokenKind_Plus = { ^null ^binary Prec_Term }
            TokenKind_Minus = { ^unary ^binary Prec_Term }
            TokenKind_Star = { ^null ^binary Prec_Factor }
            TokenKind_Slash = { ^null ^binary Prec_Factor }
            TokenKind_Number = { ^number ^null Prec_None }
            else { drop ^null ^null Prec_None }
        }
        Rule
    }

    proc next_precedence [u8] to [u8] {
        cond {
            Prec_Group = { Prec_Group }
            else { 1+ }
        }
    }

    proc parse_expression [Eval&] to [] {
        Prec_Term Eval::parse_precedence
    }

    proc parse_precedence [var this Eval&, var prec u8] to [] {
        this@ advance

        // Parse our prefix.
        this@.previous.kind@ get_rule
        xtrd(prefix) this@ swap@

        while prec@ this@.current.kind@ get_rule xtrd(prec) <= {
            this@ advance
            this@.previous.kind@ get_rule
            xtrd(infix) this@ swap@
        }
    }

    // Rule parsers
    proc grouping [var this Eval&] to [] {
        this@ parse_expression
        cond {
            this@.current.kind@ TokenKind_RightParen = {
                this@ advance
            }
            else {
                "Error: expected closing parenthesis" term::ewriteln
                exit(1)
            }
        }
    }

    proc binary [var this Eval&] to [] {
        var lhs s64
        this@.sum@ lhs!
        var op_type u8
        this@.previous.kind@ op_type!

        op_type@ get_rule xtrd(prec) next_precedence this@ swap parse_precedence
 
        this@.sum dup @ lhs@
        cond {
            op_type@ TokenKind_Plus = { + }
            op_type@ TokenKind_Minus = { - }
            op_type@ TokenKind_Star = { * }
            op_type@ TokenKind_Slash = { / }
            else {drop(3) return}
        }
        swap !
    }

    proc null [Eval&] to [] {
        drop
    }

    proc number [var this Eval&] to [] {
        cond {
            this@.previous.kind@ TokenKind_Number != {
                "Expected Number, found " term::write this@.previous@ Token::print
                exit(1)
            }
            else {
                this@.previous.number@ this@.sum!
            }
        }
    }

    proc unary [var this Eval&] to [] {
        this@ Prec_Unary parse_precedence
        this@.sum dup@ 0 swap - swap!
    }
}


const TokenKind_LeftParen [u8] { 0 }
const TokenKind_RightParen [u8] { 1 }
const TokenKind_Plus [u8] { 2 }
const TokenKind_Minus [u8] { 3 }
const TokenKind_Slash [u8] { 4 }
const TokenKind_Star [u8] { 5 }
const TokenKind_Number [u8] { 6 }
const TokenKind_Eof [u8] { 7 }
const TokenKind_Unknown [u8] { 8 }

struct Token {
    kind u8,
    number s64,
    lexeme String,

    proc print [Token] to [] {
        xtr(kind) cond {
            TokenKind_Eof= {"Eof" term::writeln}
            TokenKind_LeftParen= {"LeftParen" term::writeln}
            TokenKind_RightParen= {"RightParen" term::writeln}
            TokenKind_Plus= {"Plus" term::writeln}
            TokenKind_Minus= {"Minus" term::writeln}
            TokenKind_Star= {"Star" term::writeln}
            TokenKind_Slash= {"Slash" term::writeln}
            TokenKind_Number= {"Number: " term::write xtr(number) term::write_si_ln}
            TokenKind_Unknown= {"Unknown: " term::write xtr(lexeme) term::writeln}
            else {drop}
        }
        drop
    }
}

struct Scanner {
    start String,
    current String,

    proc new [String] to [Scanner] {
        dup Scanner
    }

    proc advance [Scanner&] to [u8] {
        0 over .current#@
        swap .current dup @ 1 String::remove_start swap !
    }

    proc is_at_end [Scanner&] to [bool] {
        .current.length@ 0=
    }

    proc is_digit [u8] to [bool] {
        dup '0'>=
        swap '9'<= and
    }

    proc lexeme [var this Scanner&] to [String] {
        this@.start.length@ this@.current.length@ -
        this@.start@ ins(length)
    }

    proc make_token [u8, Scanner&] to [Token] {
        lexeme 0 swap Token
    }

    proc number [var sum s64, var this Scanner&] to [Token] {
        sum@ '0'- sum! // Started as ASCII

        while this@ peek is_digit {
            this@ advance '0'- sum@ 10*+ sum!
        }

        TokenKind_Number sum@ this@ lexeme Token
    }

    proc peek [Scanner&] to [u8] {
        cond {
            dup is_at_end { drop TokenKind_Eof }
            else { .current@ 0 xtrd }
        }
    }

    proc scan [var this Scanner&] to [Token] {
        this@ skip_whitespace
        this@.current@ this@.start!

        cond {this@ is_at_end {
            TokenKind_Eof this@ make_token return
        }}

        this@ advance
        cond {
            dup is_digit { this@ number return }
            '('= { TokenKind_LeftParen this@ make_token }
            ')'= { TokenKind_RightParen this@ make_token }
            '+'= { TokenKind_Plus this@ make_token }
            '-'= { TokenKind_Minus this@ make_token }
            '*'= { TokenKind_Star this@ make_token }
            '/'= { TokenKind_Slash this@ make_token }
            else { drop TokenKind_Unknown this@ make_token }
        }

        return
    }
    
    proc skip_whitespace [var this Scanner&] to [] {
        while this@ peek TokenKind_Eof != {
            cond {
                this@ peek std::string::is_whitespace {
                    this@ advance drop
                }
                else {return}
            }
        }
    }
}