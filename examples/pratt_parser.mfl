import std::term
import core::String

proc entry [var argc: u64, var argv: u8**] to [] {
    cond {
        argc@ 2 != {
            "USAGE: " term::write argv@@ String::from_cstr term::write
            " \"<expr>\"" term::writeln
            return
        }
    }

    argv@ 1+@ String::from_cstr dup
    term::write " = " term::write
    Scanner::new Eval::new

    var eval: Eval
    eval!

    eval :advance
    eval :parse_expression
    eval.sum@ term::write_si_ln
}

enum Prec {
    None,
    Term,
    Factor,
    Unary,
    Group
}

struct Eval {
    scanner: Scanner,
    current: Token,
    previous: Token,
    sum: s64,

    struct Rule {
        prefix: proc[Eval&] to [],
        infix: proc[Eval&] to [],
        prec: Prec
    }

    proc new [Scanner] to [Eval] {
        TokenKind::Eof 0 "" Token dup 0 Eval
    }

    proc advance [var this: Eval&] to [] {
        this@.current@ this@.previous!

        while true {
            this@.scanner :scan
            this@.current!

            cond {
                this@.current.kind@ TokenKind::Unknown != {return}
                else {
                    "Unknown input: " term::write this@.current.lexeme@ term::writeln
                }
            }
        }
    }

    proc get_rule [TokenKind] to [Rule] {
        cond {
            TokenKind::LeftParen = { ^grouping ^null Prec::Group }
            TokenKind::Plus = { ^null ^binary Prec::Term }
            TokenKind::Minus = { ^unary ^binary Prec::Term }
            TokenKind::Star = { ^null ^binary Prec::Factor }
            TokenKind::Slash = { ^null ^binary Prec::Factor }
            TokenKind::Number = { ^number ^null Prec::None }
            else { drop ^null ^null Prec::None }
        }
        Rule
    }

    proc next_precedence [Prec] to [Prec] {
        cond {
            Prec::None = { Prec::Term }
            Prec::Term = { Prec::Factor }
            Prec::Factor = { Prec::Unary }
            Prec::Unary = { Prec::Group }
            Prec::Group = { Prec::Group }
        }
    }

    proc parse_expression [Eval&] to [] {
        Prec::Term swap Eval::parse_precedence
    }

    proc parse_precedence [var prec: Prec, var this: Eval&] to [] {
        this@ advance

        // Parse our prefix.
        this@.previous.kind@ get_rule
        xtrd(prefix) this@ swap@

        while prec@ this@.current.kind@ get_rule xtrd(prec) <= {
            this@ advance
            this@.previous.kind@ get_rule
            xtrd(infix) this@ swap@
        }
    }

    // Rule parsers
    proc grouping [var this: Eval&] to [] {
        this@ parse_expression
        cond {
            this@.current.kind@ TokenKind::RightParen = {
                this@ advance
            }
            else {
                "Error: expected closing parenthesis" term::ewriteln
                exit(1)
            }
        }
    }

    proc binary [var this: Eval&] to [] {
        var lhs: s64
        this@.sum@ lhs!
        var op_type: TokenKind
        this@.previous.kind@ op_type!

        op_type@ get_rule xtrd(prec) next_precedence this@ parse_precedence
 
        this@.sum dup @ lhs@
        cond {
            op_type@ TokenKind::Plus = { + }
            op_type@ TokenKind::Minus = { - }
            op_type@ TokenKind::Star = { * }
            op_type@ TokenKind::Slash = { / }
            else {drop(3) return}
        }
        swap !
    }

    proc null [Eval&] to [] {
        drop
    }

    proc number [var this: Eval&] to [] {
        cond {
            this@.previous.kind@ TokenKind::Number != {
                "Expected Number, found " term::write this@.previous@ Token::print
                exit(1)
            }
            else {
                this@.previous.number@ this@.sum!
            }
        }
    }

    proc unary [var this: Eval&] to [] {
        Prec::Unary this@ parse_precedence
        this@.sum dup@ 0 swap - swap!
    }
}

enum TokenKind {
  LeftParen,
  RightParen,
  Plus,
  Minus,
  Slash,
  Star,
  Number,
  Eof,
  Unknown
}

struct Token {
    kind: TokenKind,
    number: s64,
    lexeme: String,

    proc print [Token] to [] {
        xtr(kind) cond {
            TokenKind::Eof= {"Eof" term::writeln}
            TokenKind::LeftParen= {"LeftParen" term::writeln}
            TokenKind::RightParen= {"RightParen" term::writeln}
            TokenKind::Plus= {"Plus" term::writeln}
            TokenKind::Minus= {"Minus" term::writeln}
            TokenKind::Star= {"Star" term::writeln}
            TokenKind::Slash= {"Slash" term::writeln}
            TokenKind::Number= {"Number: " term::write xtr(number) term::write_si_ln}
            TokenKind::Unknown= {"Unknown: " term::write xtr(lexeme) term::writeln}
            else {drop}
        }
        drop
    }
}

struct Scanner {
    start: String,
    current: String,

    proc new [String] to [Scanner] {
        dup Scanner
    }

    proc advance [Scanner&] to [u8] {
        0 over .current#@
        swap .current dup @ 1 swap String::remove_start swap !
    }

    proc is_at_end [Scanner&] to [bool] {
        .current.length@ 0=
    }

    proc is_digit [u8] to [bool] {
        dup '0'>=
        swap '9'<= and
    }

    proc lexeme [var this: Scanner&] to [String] {
        this@.start.length@ this@.current.length@ -
        this@.start@ ins(length)
    }

    proc make_token [TokenKind, Scanner&] to [Token] {
        lexeme 0 swap Token
    }

    proc number [var sum: s64, var this: Scanner&] to [Token] {
        sum@ '0'- sum! // Started as ASCII

        while this@ peek is_digit {
            this@ advance '0'- sum@ 10*+ sum!
        }

        TokenKind::Number sum@ this@ lexeme Token
    }

    proc peek [Scanner&] to [u8] {
        cond {
            dup is_at_end { drop 0 }
            else { .current@ 0 xtrd }
        }
    }

    proc scan [var this: Scanner&] to [Token] {
        this@ skip_whitespace
        this@.current@ this@.start!

        cond {this@ is_at_end {
            TokenKind::Eof this@ make_token return
        }}

        this@ advance
        cond {
            dup is_digit { this@ number return }
            '('= { TokenKind::LeftParen this@ make_token }
            ')'= { TokenKind::RightParen this@ make_token }
            '+'= { TokenKind::Plus this@ make_token }
            '-'= { TokenKind::Minus this@ make_token }
            '*'= { TokenKind::Star this@ make_token }
            '/'= { TokenKind::Slash this@ make_token }
            else { drop TokenKind::Unknown this@ make_token }
        }

        return
    }
    
    proc skip_whitespace [var this: Scanner&] to [] {
        while this@ peek 0 != {
            cond {
                this@ peek std::string::is_whitespace {
                    this@ advance drop
                }
                else {return}
            }
        }
    }
}